{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629c435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ab42a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed search for GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "print(\"Completed search for GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c198032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_train,y_train,x_test,y_test,subtract_pixel=True):\n",
    "    x_train = x_train.astype('float32')/255\n",
    "    x_test = x_test.astype('float32')/255\n",
    "    \n",
    "    #Getting the mean of each pixel across the entire dataset \n",
    "    if subtract_pixel:\n",
    "        x_train_mean = np.mean(x_train,axis=0)\n",
    "        x_train -= x_train_mean\n",
    "        x_test -= x_test_mean\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def rotate_image(im, iterations=None):\n",
    "    if not iterations:\n",
    "        iterations = random.randint(0,3)\n",
    "    #Keep track of what angle the image has been rotated to\n",
    "    y = [0,0,0,0]\n",
    "    y[iterations] = 1\n",
    "    for i in range(iterations):\n",
    "        im = np.rot90(im)\n",
    "    return im, y\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch >180:\n",
    "        le *=0.5e-3\n",
    "    elif epoch >160:\n",
    "        le *=1e-3\n",
    "    elif epoch >120:\n",
    "        le *=1e-2\n",
    "    elif epoch >80:\n",
    "        le *=1e-1\n",
    "    print(\"Learning Rate: \", lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30407c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs, num_filters=16, \n",
    "                 kernel_size=3, \n",
    "                 strides=1, \n",
    "                 activation='relu', \n",
    "                 batch_normalization=True, \n",
    "                 conv_first=True):\n",
    "\n",
    "    #2D conv batch normalized activation stack builder\n",
    "    #output is tensor as input for next layer\n",
    "    conv = Conv2D(num_filters, \n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initialzier='he_normal'\n",
    "                  kernel_regularizer=l2(le-4))\n",
    "    x = inputs\n",
    "    \n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)    \n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    if (depth-2)%6 !=0:\n",
    "        raise ValueError(\"Depth should be 6n+2\")\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth-2)/6)\n",
    "    \n",
    "    #instantiate a keras object\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs = inputs)\n",
    "    \n",
    "    #instantate stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks): \n",
    "            strides=1\n",
    "            if stack > 0 and res_block == 0: #first layer but not first stack\n",
    "                strides = 2  #downsample\n",
    "                \n",
    "            #For each layer in each block\n",
    "            y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\n",
    "            y = resnet_layer(inputs=y, num_filters=num_filters, strides=strides)\n",
    "            \n",
    "            if stack > 0 and res_block == 0:    #first layer but not first stack\n",
    "                #linear projection residual shortcut connection to match\n",
    "                #changed dims\n",
    "                x = resnet_layer(inputs=y,\n",
    "                                num_filters=num_filters,\n",
    "                                kernel_size=1,\n",
    "                                strides=strides,\n",
    "                                activation=None\n",
    "                                batch_normalization=False)\n",
    "                x = keras.layers.add([x,y])\n",
    "                x = Activation('relu')(x)\n",
    "            num_filters *= 2\n",
    "        \n",
    "        #Add classifier on top\n",
    "        x = AveragePooling2D(pool_size=8)(x)\n",
    "        y = Flatten()(x)\n",
    "        outputs = Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(y)\n",
    "        output_model = Model(inputs=inputs,outputs=outputs)\n",
    "        return output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rotated_data(Train, Test, subtract_pixel_mean=True):\n",
    "    model_name='cifar100SSL'\n",
    "    xy_rot_train = list(zip(*[rotate_image(im) for im in Train[0]]))\n",
    "    xy_rot_test = list(zip(*[rotate_image(im) for im in Test[0]]))\n",
    "    \n",
    "    #x_rot refers to rotated image\n",
    "    #x_rot refers to how much it was rotated (0,90,180,270)\n",
    "    \n",
    "    x_rot_train = np.array(xy_rot_train[0][:]).astype('float32'/255)\n",
    "    t_rot_train = np.array(xy_rot_train[1][:])\n",
    "    \n",
    "    x_rot_ttest = np.array(xy_rot_test[0][:]).astype('float32'/255)\n",
    "    y_rot_train = np.array(xy_rot_test[1][:])\n",
    "    \n",
    "    if subtract_pixel_mean:\n",
    "        x_rot_train_mean = np.mean(x_rot_train, axis=0)\n",
    "        x_rot_train -= x_rot_train_mean \n",
    "        x_rot_test -= x_rot_test_mean\n",
    "    \n",
    "    return x_rot_train, y_rot_train, x_rot_test, y_rot_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
